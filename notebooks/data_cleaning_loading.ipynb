{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning sample and Working with Local Database connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 20:16:39,568 - INFO - ‚úÖ CSV file '../merged_data.csv' loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "      <th>source_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15208</td>\n",
       "      <td>NEUROPRO CARE \\nPrice 5500 birr \\nTelegram @Lo...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15208.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15207</td>\n",
       "      <td>ENSURE 850GM\\nPrice 3800 birr \\nTelegram https...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15207.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15206</td>\n",
       "      <td>NIDO 1+ 2.2KG \\nPrice 6500 birr \\nTelegram @Lo...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15206.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15205</td>\n",
       "      <td>Enfagrow A+\\nPrice 5500 birr \\nTelegram https:...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15205.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15204</td>\n",
       "      <td>go &amp; grow 850gm\\nPrice 5500 birr \\nTelegram ht...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15204.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Channel Title    Channel Username     ID  \\\n",
       "0  Lobelia pharmacy and cosmetics  @lobelia4cosmetics  15208   \n",
       "1  Lobelia pharmacy and cosmetics  @lobelia4cosmetics  15207   \n",
       "2  Lobelia pharmacy and cosmetics  @lobelia4cosmetics  15206   \n",
       "3  Lobelia pharmacy and cosmetics  @lobelia4cosmetics  15205   \n",
       "4  Lobelia pharmacy and cosmetics  @lobelia4cosmetics  15204   \n",
       "\n",
       "                                             Message  \\\n",
       "0  NEUROPRO CARE \\nPrice 5500 birr \\nTelegram @Lo...   \n",
       "1  ENSURE 850GM\\nPrice 3800 birr \\nTelegram https...   \n",
       "2  NIDO 1+ 2.2KG \\nPrice 6500 birr \\nTelegram @Lo...   \n",
       "3  Enfagrow A+\\nPrice 5500 birr \\nTelegram https:...   \n",
       "4  go & grow 850gm\\nPrice 5500 birr \\nTelegram ht...   \n",
       "\n",
       "                        Date                           Media Path  \\\n",
       "0  2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15208.jpg   \n",
       "1  2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15207.jpg   \n",
       "2  2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15206.jpg   \n",
       "3  2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15205.jpg   \n",
       "4  2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15204.jpg   \n",
       "\n",
       "           source_channel  \n",
       "0  lobelia4cosmetics_data  \n",
       "1  lobelia4cosmetics_data  \n",
       "2  lobelia4cosmetics_data  \n",
       "3  lobelia4cosmetics_data  \n",
       "4  lobelia4cosmetics_data  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 20:16:39,593 - INFO - ‚úÖ Duplicates removed from dataset.\n",
      "2025-01-31 20:16:39,608 - INFO - ‚úÖ Date column formatted to datetime.\n",
      "2025-01-31 20:16:39,612 - INFO - ‚úÖ Missing values filled.\n",
      "2025-01-31 20:16:39,646 - INFO - ‚úÖ Data cleaning completed successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_title</th>\n",
       "      <th>channel_username</th>\n",
       "      <th>message_id</th>\n",
       "      <th>message</th>\n",
       "      <th>message_date</th>\n",
       "      <th>media_path</th>\n",
       "      <th>source_channel</th>\n",
       "      <th>emoji_used</th>\n",
       "      <th>youtube_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15208</td>\n",
       "      <td>NEUROPRO CARE  Price 5500 birr  Telegram @Lobe...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15208.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "      <td>üëâ‚òéüèçüèçüèç</td>\n",
       "      <td>No YouTube link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15207</td>\n",
       "      <td>ENSURE 850GM Price 3800 birr  Telegram https:/...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15207.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "      <td>üëâ‚òéüèçüèçüèç</td>\n",
       "      <td>No YouTube link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15206</td>\n",
       "      <td>NIDO 1+ 2.2KG  Price 6500 birr  Telegram @Lobe...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15206.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "      <td>üëâ‚òéüèçüèçüèç</td>\n",
       "      <td>No YouTube link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15205</td>\n",
       "      <td>Enfagrow A+ Price 5500 birr  Telegram https://...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15205.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "      <td>üëâ‚òéüèçüèçüèç</td>\n",
       "      <td>No YouTube link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lobelia pharmacy and cosmetics</td>\n",
       "      <td>@lobelia4cosmetics</td>\n",
       "      <td>15204</td>\n",
       "      <td>go &amp; grow 850gm Price 5500 birr  Telegram http...</td>\n",
       "      <td>2025-01-31 12:40:44+00:00</td>\n",
       "      <td>photos/@lobelia4cosmetics_15204.jpg</td>\n",
       "      <td>lobelia4cosmetics_data</td>\n",
       "      <td>üëâ‚òéüèçüèçüèç</td>\n",
       "      <td>No YouTube link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    channel_title    channel_username  message_id  \\\n",
       "0  Lobelia pharmacy and cosmetics  @lobelia4cosmetics       15208   \n",
       "1  Lobelia pharmacy and cosmetics  @lobelia4cosmetics       15207   \n",
       "2  Lobelia pharmacy and cosmetics  @lobelia4cosmetics       15206   \n",
       "3  Lobelia pharmacy and cosmetics  @lobelia4cosmetics       15205   \n",
       "4  Lobelia pharmacy and cosmetics  @lobelia4cosmetics       15204   \n",
       "\n",
       "                                             message  \\\n",
       "0  NEUROPRO CARE  Price 5500 birr  Telegram @Lobe...   \n",
       "1  ENSURE 850GM Price 3800 birr  Telegram https:/...   \n",
       "2  NIDO 1+ 2.2KG  Price 6500 birr  Telegram @Lobe...   \n",
       "3  Enfagrow A+ Price 5500 birr  Telegram https://...   \n",
       "4  go & grow 850gm Price 5500 birr  Telegram http...   \n",
       "\n",
       "               message_date                           media_path  \\\n",
       "0 2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15208.jpg   \n",
       "1 2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15207.jpg   \n",
       "2 2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15206.jpg   \n",
       "3 2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15205.jpg   \n",
       "4 2025-01-31 12:40:44+00:00  photos/@lobelia4cosmetics_15204.jpg   \n",
       "\n",
       "           source_channel emoji_used    youtube_links  \n",
       "0  lobelia4cosmetics_data      üëâ‚òéüèçüèçüèç  No YouTube link  \n",
       "1  lobelia4cosmetics_data      üëâ‚òéüèçüèçüèç  No YouTube link  \n",
       "2  lobelia4cosmetics_data      üëâ‚òéüèçüèçüèç  No YouTube link  \n",
       "3  lobelia4cosmetics_data      üëâ‚òéüèçüèçüèç  No YouTube link  \n",
       "4  lobelia4cosmetics_data      üëâ‚òéüèçüèçüèç  No YouTube link  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 20:16:39,673 - INFO - ‚úÖ Cleaned data saved successfully to 'cleaned_data.csv'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned data saved successfully to 'cleaned_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import emoji\n",
    "from IPython.display import display  # Ensures DataFrames are shown properly in Jupyter\n",
    "\n",
    "# Ensure logs folder exists\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "\n",
    "# Configure logging for Jupyter Notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"./logs/data_cleaning.log\"),  # Save logs to file\n",
    "        logging.StreamHandler()  # Display logs in Jupyter Notebook\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\" Load CSV file into a Pandas DataFrame. \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        logging.info(f\"‚úÖ CSV file '{file_path}' loaded successfully.\")\n",
    "        display(df.head())  # Show first few rows in Jupyter Notebook\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error loading CSV file: {e}\")\n",
    "        raise\n",
    "\n",
    "def extract_emojis(text):\n",
    "    \"\"\" Extract emojis from text, return 'No emoji' if none found. \"\"\"\n",
    "    emojis = ''.join(c for c in text if c in emoji.EMOJI_DATA)\n",
    "    return emojis if emojis else \"No emoji\"\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\" Remove emojis from the message text. \"\"\"\n",
    "    return ''.join(c for c in text if c not in emoji.EMOJI_DATA)\n",
    "\n",
    "def extract_youtube_links(text):\n",
    "    \"\"\" Extract YouTube links from text, return 'No YouTube link' if none found. \"\"\"\n",
    "    youtube_pattern = r\"(https?://(?:www\\.)?(?:youtube\\.com|youtu\\.be)/[^\\s]+)\"\n",
    "    links = re.findall(youtube_pattern, str(text))  # Ensure text is a string\n",
    "    return ', '.join(links) if links else \"No YouTube link\"\n",
    "\n",
    "def remove_youtube_links(text):\n",
    "    \"\"\" Remove YouTube links from the message text. \"\"\"\n",
    "    youtube_pattern = r\"https?://(?:www\\.)?(?:youtube\\.com|youtu\\.be)/[^\\s]+\"\n",
    "    return re.sub(youtube_pattern, '', str(text)).strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\" Standardize text by removing newline characters and unnecessary spaces. \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"No Message\"\n",
    "    return re.sub(r'\\n+', ' ', str(text)).strip()\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \"\"\" Perform all cleaning and standardization steps while avoiding SettingWithCopyWarning. \"\"\"\n",
    "    try:\n",
    "        df = df.drop_duplicates(subset=[\"ID\"]).copy()  # Ensure a new copy\n",
    "        logging.info(\"‚úÖ Duplicates removed from dataset.\")\n",
    "\n",
    "        # ‚úÖ Convert Date to datetime format\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df['Date'] = df['Date'].where(df['Date'].notna(), None)\n",
    "        logging.info(\"‚úÖ Date column formatted to datetime.\")\n",
    "\n",
    "        # ‚úÖ Convert 'ID' to integer for PostgreSQL BIGINT compatibility\n",
    "        df['ID'] = pd.to_numeric(df['ID'], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "        # ‚úÖ Fill missing values\n",
    "        df['Message'] = df['Message'].fillna(\"No Message\")\n",
    "        df['Media Path'] = df['Media Path'].fillna(\"No Media\")\n",
    "        logging.info(\"‚úÖ Missing values filled.\")\n",
    "\n",
    "        # ‚úÖ Standardize text columns\n",
    "        for col in [\"Channel Title\", \"Channel Username\", \"Message\", \"Media Path\"]:\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "        df[\"Message\"] = df[\"Message\"].apply(clean_text)\n",
    "\n",
    "        # ‚úÖ Extract emojis and store them in a new column\n",
    "        df[\"emoji_used\"] = df[\"Message\"].apply(extract_emojis)\n",
    "\n",
    "        # ‚úÖ Remove emojis from message text\n",
    "        df[\"Message\"] = df[\"Message\"].apply(remove_emojis)\n",
    "\n",
    "        # ‚úÖ Extract and remove YouTube links\n",
    "        df[\"youtube_links\"] = df[\"Message\"].apply(extract_youtube_links)\n",
    "        df[\"Message\"] = df[\"Message\"].apply(remove_youtube_links)\n",
    "\n",
    "        # ‚úÖ Rename columns for PostgreSQL compatibility\n",
    "        df = df.rename(columns={\n",
    "            \"Channel Title\": \"channel_title\",\n",
    "            \"Channel Username\": \"channel_username\",\n",
    "            \"ID\": \"message_id\",\n",
    "            \"Message\": \"message\",\n",
    "            \"Date\": \"message_date\",\n",
    "            \"Media Path\": \"media_path\",\n",
    "            \"emoji_used\": \"emoji_used\",\n",
    "            \"youtube_links\": \"youtube_links\"\n",
    "        })\n",
    "\n",
    "        logging.info(\"‚úÖ Data cleaning completed successfully.\")\n",
    "        display(df.head())  # Show cleaned DataFrame in Jupyter Notebook\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Data cleaning error: {e}\")\n",
    "        raise\n",
    "\n",
    "def save_cleaned_data(df, output_path):\n",
    "    \"\"\" Save cleaned data to a new CSV file. \"\"\"\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        logging.info(f\"‚úÖ Cleaned data saved successfully to '{output_path}'.\")\n",
    "        print(f\"‚úÖ Cleaned data saved successfully to '{output_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error saving cleaned data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Run each step interactively in Jupyter Notebook\n",
    "input_csv = '../merged_data.csv'\n",
    "output_csv = 'cleaned_data.csv'\n",
    "\n",
    "# Load the data\n",
    "df = load_csv(input_csv)\n",
    "\n",
    "# Clean the data\n",
    "cleaned_df = clean_dataframe(df)\n",
    "\n",
    "# Save the cleaned data\n",
    "save_cleaned_data(cleaned_df, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 19:19:38,915 - INFO - ‚úÖ CSV file '../merged_data.csv' loaded successfully.\n",
      "2025-02-02 19:19:38,934 - INFO - ‚úÖ Duplicates removed from dataset.\n",
      "2025-02-02 19:19:39,001 - INFO - ‚úÖ Date column formatted to datetime.\n",
      "2025-02-02 19:19:39,053 - INFO - ‚úÖ Missing values filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_HOST: your_db_host\n",
      "DB_NAME: your_db_name\n",
      "DB_USER: your_db_user\n",
      "DB_PASSWORD: your_db_password\n",
      "DB_PORT: 5432  # Default PostgreSQL port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-02 19:19:39,081 - INFO - ‚úÖ Text columns standardized.\n",
      "2025-02-02 19:19:39,101 - INFO - ‚úÖ Emojis extracted and stored in 'emoji_used' column.\n",
      "2025-02-02 19:19:39,133 - INFO - ‚úÖ YouTube links extracted and stored in 'youtube_links' column.\n",
      "2025-02-02 19:19:39,143 - INFO - ‚úÖ Data cleaning completed successfully.\n",
      "2025-02-02 19:19:39,164 - INFO - ‚úÖ Cleaned data saved successfully to 'cleaned_data.csv'.\n",
      "2025-02-02 19:19:39,184 - ERROR - ‚ùå Error establishing database connection: invalid literal for int() with base 10: '5432  # Default PostgreSQL port'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned data saved successfully to 'cleaned_data.csv'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '5432  # Default PostgreSQL port'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 177\u001b[0m\n\u001b[1;32m    174\u001b[0m save_cleaned_data(cleaned_df, output_csv)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# Store the cleaned data in the database\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mget_db_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m store_data_in_db(cleaned_df, table_name, engine)\n",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mget_db_connection\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Create and return database engine. \"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDB_USER\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDB_PASSWORD\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m@\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDB_HOST\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDB_PORT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDB_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Database connection established successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/Codes/ethiopian-medical-data-warehouse/venv/lib/python3.12/site-packages/sqlalchemy/util/deprecations.py:281\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    275\u001b[0m         _warn_with_version(\n\u001b[1;32m    276\u001b[0m             messages[m],\n\u001b[1;32m    277\u001b[0m             versions[m],\n\u001b[1;32m    278\u001b[0m             version_warnings[m],\n\u001b[1;32m    279\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    280\u001b[0m         )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/ethiopian-medical-data-warehouse/venv/lib/python3.12/site-packages/sqlalchemy/engine/create.py:549\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty_in_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# create url.URL object\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43m_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m u, plugins, kwargs \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_instantiate_plugins(kwargs)\n\u001b[1;32m    553\u001b[0m entrypoint \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_get_entrypoint()\n",
      "File \u001b[0;32m~/Codes/ethiopian-medical-data-warehouse/venv/lib/python3.12/site-packages/sqlalchemy/engine/url.py:856\u001b[0m, in \u001b[0;36mmake_url\u001b[0;34m(name_or_url)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given a string, produce a new URL instance.\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03mThe format of the URL generally follows `RFC-1738\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m \n\u001b[1;32m    853\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_url, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_url, URL) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    858\u001b[0m     name_or_url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sqla_is_testing_if_this_is_a_mock_object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m ):\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mArgumentError(\n\u001b[1;32m    861\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected string or URL object, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_or_url\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    862\u001b[0m     )\n",
      "File \u001b[0;32m~/Codes/ethiopian-medical-data-warehouse/venv/lib/python3.12/site-packages/sqlalchemy/engine/url.py:917\u001b[0m, in \u001b[0;36m_parse_url\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    914\u001b[0m     name \u001b[38;5;241m=\u001b[39m components\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m components[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 917\u001b[0m         components[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m URL\u001b[38;5;241m.\u001b[39mcreate(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponents)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '5432  # Default PostgreSQL port'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import emoji\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Ensure logs folder exists\n",
    "os.makedirs(\"../logs\", exist_ok=True)\n",
    "\n",
    "# Configure logging to write to file & display in Jupyter Notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"../logs/data_cleaning.log\"),  # Log to file\n",
    "        logging.StreamHandler()  # Log to Jupyter Notebook output\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\" Create and return database engine. \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "        logging.info(\"‚úÖ Database connection established successfully.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error establishing database connection: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_csv(file_path):\n",
    "    \"\"\" Load CSV file into a Pandas DataFrame. \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        logging.info(f\"‚úÖ CSV file '{file_path}' loaded successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error loading CSV file: {e}\")\n",
    "        raise\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\" Standardize text by removing newline characters and unnecessary spaces. \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"No Message\"\n",
    "    return re.sub(r'\\n+', ' ', text).strip()\n",
    "\n",
    "def extract_emojis(text):\n",
    "    \"\"\" Extract emojis from text, return 'No emoji' if none found. \"\"\"\n",
    "    emojis = ''.join(c for c in text if c in emoji.EMOJI_DATA)\n",
    "    return emojis if emojis else \"No emoji\"\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\" Remove emojis from the message text. \"\"\"\n",
    "    return ''.join(c for c in text if c not in emoji.EMOJI_DATA)\n",
    "\n",
    "def extract_youtube_links(text):\n",
    "    \"\"\" Extract YouTube links from text, return 'No YouTube link' if none found. \"\"\"\n",
    "    youtube_pattern = r\"(https?://(?:www\\.)?(?:youtube\\.com|youtu\\.be)/[^\\s]+)\"\n",
    "    links = re.findall(youtube_pattern, text)\n",
    "    return ', '.join(links) if links else \"No YouTube link\"\n",
    "\n",
    "def remove_youtube_links(text):\n",
    "    \"\"\" Remove YouTube links from the message text. \"\"\"\n",
    "    youtube_pattern = r\"https?://(?:www\\.)?(?:youtube\\.com|youtu\\.be)/[^\\s]+\"\n",
    "    return re.sub(youtube_pattern, '', text).strip()\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    \"\"\" Perform all cleaning and standardization steps while avoiding SettingWithCopyWarning. \"\"\"\n",
    "    try:\n",
    "        df = df.drop_duplicates(subset=[\"ID\"]).copy()  # Ensure a new copy\n",
    "        logging.info(\"‚úÖ Duplicates removed from dataset.\")\n",
    "\n",
    "        # ‚úÖ Convert Date to datetime format, replacing NaT with None\n",
    "        df.loc[:, 'Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df.loc[:, 'Date'] = df['Date'].where(df['Date'].notna(), None)\n",
    "        logging.info(\"‚úÖ Date column formatted to datetime.\")\n",
    "\n",
    "        # ‚úÖ Convert 'ID' to integer for PostgreSQL BIGINT compatibility\n",
    "        df.loc[:, 'ID'] = pd.to_numeric(df['ID'], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "        # ‚úÖ Fill missing values\n",
    "        df.loc[:, 'Message'] = df['Message'].fillna(\"No Message\")\n",
    "        df.loc[:, 'Media Path'] = df['Media Path'].fillna(\"No Media\")\n",
    "        logging.info(\"‚úÖ Missing values filled.\")\n",
    "\n",
    "        # ‚úÖ Standardize text columns\n",
    "        df.loc[:, 'Channel Title'] = df['Channel Title'].str.strip()\n",
    "        df.loc[:, 'Channel Username'] = df['Channel Username'].str.strip()\n",
    "        df.loc[:, 'Message'] = df['Message'].apply(clean_text)\n",
    "        df.loc[:, 'Media Path'] = df['Media Path'].str.strip()\n",
    "        logging.info(\"‚úÖ Text columns standardized.\")\n",
    "\n",
    "        # ‚úÖ Extract emojis and store them in a new column\n",
    "        df.loc[:, 'emoji_used'] = df['Message'].apply(extract_emojis)\n",
    "        logging.info(\"‚úÖ Emojis extracted and stored in 'emoji_used' column.\")\n",
    "        \n",
    "        # ‚úÖ Remove emojis from message text\n",
    "        df.loc[:, 'Message'] = df['Message'].apply(remove_emojis)\n",
    "\n",
    "        # ‚úÖ Extract YouTube links into a separate column\n",
    "        df.loc[:, 'youtube_links'] = df['Message'].apply(extract_youtube_links)\n",
    "        logging.info(\"‚úÖ YouTube links extracted and stored in 'youtube_links' column.\")\n",
    "\n",
    "        # ‚úÖ Remove YouTube links from message text\n",
    "        df.loc[:, 'Message'] = df['Message'].apply(remove_youtube_links)\n",
    "\n",
    "        # ‚úÖ Rename columns to match PostgreSQL schema\n",
    "        df = df.rename(columns={\n",
    "            \"Channel Title\": \"channel_title\",\n",
    "            \"Channel Username\": \"channel_username\",\n",
    "            \"ID\": \"message_id\",\n",
    "            \"Message\": \"message\",\n",
    "            \"Date\": \"message_date\",\n",
    "            \"Media Path\": \"media_path\",\n",
    "            \"emoji_used\": \"emoji_used\",\n",
    "            \"youtube_links\": \"youtube_links\"\n",
    "        })\n",
    "\n",
    "        logging.info(\"‚úÖ Data cleaning completed successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Data cleaning error: {e}\")\n",
    "        raise\n",
    "\n",
    "def save_cleaned_data(df, output_path):\n",
    "    \"\"\" Save cleaned data to a new CSV file. \"\"\"\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        logging.info(f\"‚úÖ Cleaned data saved successfully to '{output_path}'.\")\n",
    "        print(f\"‚úÖ Cleaned data saved successfully to '{output_path}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error saving cleaned data: {e}\")\n",
    "        raise\n",
    "\n",
    "def store_data_in_db(df, table_name, engine):\n",
    "    \"\"\" Store cleaned data in the database. \"\"\"\n",
    "    try:\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "        logging.info(f\"‚úÖ Cleaned data stored successfully in table '{table_name}'.\")\n",
    "        print(f\"‚úÖ Cleaned data stored successfully in table '{table_name}'.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"‚ùå Error storing data in database: {e}\")\n",
    "        raise\n",
    "\n",
    "# Run each step interactively in Jupyter Notebook\n",
    "input_csv = '../merged_data.csv'\n",
    "output_csv = 'cleaned_data.csv'\n",
    "table_name = 'cleaned_data'\n",
    "\n",
    "# Load the data\n",
    "df = load_csv(input_csv)\n",
    "\n",
    "# Clean the data\n",
    "cleaned_df = clean_dataframe(df)\n",
    "\n",
    "# Save the cleaned data\n",
    "save_cleaned_data(cleaned_df, output_csv)\n",
    "\n",
    "# Store the cleaned data in the database\n",
    "engine = get_db_connection()\n",
    "store_data_in_db(cleaned_df, table_name, engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
